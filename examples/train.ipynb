{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CELTIC Model\n",
    "\n",
    "In this notebook, we demonstrate the process of training the CELTIC model. Using preprocessed images and context data, we initialize the experiment, configure the model, and run the training process. The trained model is saved in a local folder for later use in predictions (see `predict.ipynb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celtic.utils.functions import initialize_experiment, download_resources\n",
    "from celtic.train import train\n",
    "import os\n",
    "\n",
    "# Presets\n",
    "organelle = 'microtubules'\n",
    "resources_dir = '../resources'\n",
    "\n",
    "# Note: This path is not available to users at the moment. \n",
    "# A new method for accessing the single-cell data path externally will be released soon.\n",
    "# Users have to wait for this update to gain access to the the single cell data.\n",
    "path_single_cells = f'/sise/assafzar-group/assafzar/Nitsan/hipsc_single_cell_image_dataset/{organelle}/fov_processed/cells/source'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download resources\n",
    "if not os.path.exists(resources_dir):\n",
    "    shared_folder_link = 'https://drive.google.com/drive/folders/1KTzb3fzwjH5ffSLtLNHuYiLiPg2p2VUf?usp=sharing'\n",
    "    download_resources(shared_folder_link, os.path.dirname(resources_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Experiment\n",
    "\n",
    "This step initializes the experiment by creating a local folder to store the training files. It also sets up CSV files that contain the paths to the images, and if contexts are used, it includes CSV files with the context data. In this example, we provide the microtubules context files. The process of context creation is explained in the `context_creation.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the experiment will be saved in: ./experiments/train/microtubules/2025-01-11-21-42-40\n"
     ]
    }
   ],
   "source": [
    "path_run_dir, context_model_config = initialize_experiment(organelle, 'train', resources_dir)\n",
    "print(\"the experiment will be saved in:\", path_run_dir)\n",
    "\n",
    "path_images_csv = [f'{resources_dir}/{organelle}/metadata/{item}_images.csv' for item in ['train', 'valid']]\n",
    "path_context_csv = [f'{resources_dir}/{organelle}/metadata/{item}_context.csv' for item in ['train', 'valid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training\n",
    "\n",
    "This step starts the training process using the specified parameters, including image paths, context data, and model configuration. The results are saved in the local folder of the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.run_training(path_run_dir,\n",
    "                    path_images_csv, \n",
    "                    path_context_csv,\n",
    "                    path_single_cells, \n",
    "                    masked = True,\n",
    "                    transforms = context_model_config['transforms'],\n",
    "                    patch_size = context_model_config['train_patch_size'],\n",
    "                    iterations = 60_000,\n",
    "                    batch_size = 24,\n",
    "                    learning_rate = 0.001,\n",
    "                    context_features = context_model_config['context_features'], \n",
    "                    daft_embedding_factor = context_model_config['daft_embedding_factor'], \n",
    "                    daft_scale_activation = context_model_config['daft_scale_activation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
